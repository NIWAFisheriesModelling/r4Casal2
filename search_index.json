[["index.html", "r4Casal2 Chapter 1 Welcolme to r4Casal2", " r4Casal2 C.Marsh 2022-06-27 Chapter 1 Welcolme to r4Casal2 This book demonstrates functionality of the r4Casal2 R package. This is an R package that works with the Casal2 base R-library found here, although it is advised to use the R-library that is included with the Casal2 binary and usermanual you acquired. The Casal2 base R-library is responsible for reading in output and interacting with Casal2 configuration files. The r4Casal2 R package has been built for summarising and visualising objects read in from the base Casal2 R-library. All functions in this package should be documented using the roxygen syntax with input parameters available using the ? query. For example ?get_fisheries. To get a list of functions and general info on the package you can use library(help=\"r4Casal2\") or see Section 2 for another list library(r4Casal2) library(Casal2) library(knitr) library(ggplot2) library(dplyr) library(reshape2) The core functionality of r4Casal2 are its accessor functions. These are functions that will return a specific object from a range of Casal2 objects in long format that are ggplot, dplyr friendly. Most accessors start with get_ and should be self explanatory. There are some plotting functions, but I have found that I often want to custom ggplots and so mainly have custom plots. The accessors are coded to deal with three types of outpus. These are; extract.mpd() where Casal2 has been run with default report style. These objects are of class casal2MPD which are set by the Casal2 base function extract.mpd() where Casal2 has been run with tabular reports casal2 --tabular or casal2 -t. These objects are of class casal2TAB which are set by the Casal2 base function list this is a list of casal2MPD which is a useful format for comparing MPD runs see Section 5 "],["functionlist.html", "Chapter 2 A list of key functions in the r4Casal2 package 2.1 Accessor functions 2.2 Other useful functions", " Chapter 2 A list of key functions in the r4Casal2 package 2.1 Accessor functions get_derived_quanitites() or for lazy people (like my self) get_dqs(). These will return all the derived quantities for a model output. get_selectivities will return a data frame with all the selectivity reports for a model output. get_selectivities_by_year will return a data frame with all the reports of type selectivity_by_year from a model output. get_catchabilities will return a data frame with all the catchability reports for a model output. get_fisheries will return a data frame with information from an instantaneous_mortality process for a model output. get_BH_recruitment will return a data frame with information from a recruitment_beverton_holt process for a model output. get_abundance_observations will return a data frame with information from an abundance or biomass observation for a model output. get_composition_observations will return a data frame with information from an proportion_at_length, proportion_at_age, process_removals_by_age and process_removals_by_length observation for a model output. get_tag_recapture_observations will return a data frame with information from an tag_recapture_by_length_for_growth, tag_recapture_by_length and tag_recapture_by_age observation for a model output. get_projections will return a data frame of all projection reports from a model output. get_partition will return a data frame with partition data from partition report. get_inital_partition will return a data frame with initial partition initialisation_partition report. get_simulated_age_resids Will reformat simulated data read in by the read.simulated.data function. 2.2 Other useful functions aggregate_objective_report This trys and reformats the an objective function report to be “similar” to CASALs output. create_simulation_reports This will create a range of @report.type=simulated_observation Casal2 reports that can help set up simulations. See Section 7 on why you want to do this. summarise_config Will summaris input files see Section 3 "],["summariseinputs.html", "Chapter 3 Summarise configuration inputs 3.1 Example files", " Chapter 3 Summarise configuration inputs The r4Casal2 has some functions that summarise a set of input files and returns a summary of the key model attributes. It can be difficult to know all the working parts in a Casal2 model. This is compouned when users often make tweaks during an assessment and so the initial assumptions will not correspond to the final assumptions. The key function is summarise_config 3.1 Example files config_dir = system.file(&quot;extdata&quot;, &quot;TestModelComplex&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) ## This function is the key function will read a Casal config file and report useful information ## should be used when describing model structures and assumptions ## as well as validation. summary = summarise_config(config_dir, config_file = &quot;config.csl2&quot;, quiet = T) names(summary) ## [1] &quot;category_df&quot; &quot;estimate_df&quot; &quot;full_category_df&quot; ## [4] &quot;method_df&quot; &quot;catch_df&quot; &quot;time_step_df&quot; ## [7] &quot;time_step_df_just_lab&quot; &quot;obs_year_df&quot; &quot;model_years&quot; ## [10] &quot;model_ages&quot; &quot;model_length_bins&quot; &quot;M_by_category&quot; catches_melted = melt(summary$catch_df, id.vars = c(&quot;process&quot;, &quot;year&quot;)) ggplot(catches_melted, aes(x = year, y = value, col = variable)) + geom_line(size = 1.5) + labs(x = &quot;Year&quot;, y = &quot;Catch (t)&quot;, col = &quot;Fishery&quot;) ggplot(summary$obs_year_df, aes(x = year, y = observation, col = observation, size = active)) + geom_point() + guides(colour = &quot;none&quot;, size = &quot;none&quot;) ## Warning: Removed 509 rows containing missing values (geom_point). kable(x = summary$time_step_df, caption = &quot;Annual cycle&quot;) (#tab:annual_cycle)Annual cycle Time-step Processes (type) age_size_W_male (assumed growth) age_size_E_male (assumed growth) age_size_W_female (assumed growth) age_size_E_female (assumed growth) Oct_Nov Wrtn (transition_category), Ertn (transition_category), Instant_mortality (mortality_instantaneous) 0.25 0.25 0.25 0.25 Dec_Mar recruit_W (recruitment_beverton_holt), recruit_E (recruitment_beverton_holt), Instant_mortality (mortality_instantaneous) 0.6 0.6 0.6 0.6 Apr_Jun Whome (transition_category), Instant_mortality (mortality_instantaneous) 0.9 0.9 0.9 0.9 End_Jun Wspmg (transition_category), Espmg (transition_category) 0.9 0.9 0.9 0.9 Jul_Sep Ageing (ageing), Instant_mortality (mortality_instantaneous) 0.0 0.0 0.0 0.0 kable(x = summary$full_category_df, caption = &quot;Category information&quot;) Table 3.1: Category information Category AgeLength LengthWeight Distribution male.west.sa age_size_W_male (von_bertalanffy) Length_weight (basic) normal male.east.cr age_size_E_male (von_bertalanffy) Length_weight (basic) normal male.west.cr age_size_W_male (von_bertalanffy) Length_weight (basic) normal male.west.wc age_size_W_male (von_bertalanffy) Length_weight (basic) normal male.east.cs age_size_E_male (von_bertalanffy) Length_weight (basic) normal female.west.sa age_size_W_female (von_bertalanffy) Length_weight (basic) normal female.east.cr age_size_E_female (von_bertalanffy) Length_weight (basic) normal female.west.cr age_size_W_female (von_bertalanffy) Length_weight (basic) normal female.west.wc age_size_W_female (von_bertalanffy) Length_weight (basic) normal female.east.cs age_size_E_female (von_bertalanffy) Length_weight (basic) normal kable(x = summary$estimate_df, caption = &quot;Estimate summary&quot;) Table 3.2: Estimate summary label same prior lower_bound upper_bound CSacousq - lognormal 0.01 4.53 WCacousq - lognormal 0.01 3.35 CRsumq - lognormal 0.016 0.51 SAsumq - lognormal 0.020 0.51 SAautq - lognormal 0.020 0.51 CR_process_error - lognormal 0.0 1 SA_process_error - uniform 0.0 1 B0_E_with_total_log_b0_prior - uniform 12.6 16.2 B0_W_with_proportion_prior - beta 0.11 0.59 YCS_E - lognormal 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 YCS_W - lognormal 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 0.06 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 8.60 M_male_x0 - uniform 5.1 9.1 M_male_y0 - uniform 0.01 0.30 M_male_y1 - uniform 0.5 2.0 M_male_y2 - uniform 0.5 2.0 M_female_x0 - uniform 5.1 9.1 M_female_y0 - uniform 0.01 0.30 M_female_y1 - uniform 0.5 2.0 M_female_y2 - uniform 0.5 2.0 sel_Whome - uniform 0.01 0.01 0.01 0 0 0 0 1 1 1 1 1 1 1 1 1 sel_Espmg_male - uniform 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 sel_Wspmg_male - uniform 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 sel_Espmg_female - uniform 0 0 0 0 0 0 0 0.6 1 1 1 1 1 1 1 1 sel_Wspmg_female - uniform 0 0 0 0 0 0 0 0.6 1 1 1 1 1 1 1 1 Enspsl_mu - uniform 64 84 Enspsl_s_l - uniform 4 44 Enspsl_s_r - uniform 4 44 Wnspsl_mu - uniform 64 84 Wnspsl_s_l - uniform 4 44 Wnspsl_s_r - uniform 4 44 Espsl_a50 - uniform 6 80 Espsl_ato95 - uniform 4 60 Wspsl_shift_param - normal_by_stdev -10.24 2.24 CRsl_mu - uniform 64 84 CRsl_s_l - uniform 4 44 CRsl_s_r - uniform 4 44 SAsl_mu - uniform 64 84 SAsl_s_l - uniform 4 44 SAsl_s_r - uniform 4 44 "],["mpd-summaries.html", "Chapter 4 MPD summaries 4.1 Single Model Output 4.2 Multiple Casal2 runs with -i or -s", " Chapter 4 MPD summaries 4.1 Single Model Output file_name = system.file(&quot;extdata&quot;, &quot;estimate.out&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) mpd = extract.mpd(file = file_name) 4.1.1 Model Convergence There are a range of appproaches for checking your model has converged. The approaches we will be working through include checking the hessian is positive definite, checking parameters are not running to bounds and reestimate with random starting locations. When estimating models in Casal2, it is recommended to have the following report included @report covariance_matrix type covariance_matrix ## or the Hessian @report hessian_matrix type hessian_matrix When estimation is complete and you have read in the Casal2 output using Casal2::extract.mpd(). # file name mpd_file_name = system.file(&quot;extdata&quot;, &quot;PosteriorPredictiveChecks&quot;,&quot;estimate.log&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) # read in output mpd = extract.mpd(file = mpd_file_name) # is covariance symetric isSymmetric(mpd$covar$covariance_matrix) # is hessian invertable is_matrix_invertable(mpd$hess$hessian_matrix) Once these are satisfied you will have more confidence in your standard errors, in addition to being able to run MCMC run mode. Another useful convergence diagnostic is re-estimating Casal2 at difference starting locations. The function used for this is ?generate.starting.pars. This will read a Casal2 config file that contains all the @estimate definitions are generate a bunch of random starting values in the format of useable for -i in Casal2. 4.1.2 Data Weighting Some pseudo r code to help with data weighting according to Francis (2011) with multinomial data. #&#39; #&#39; This is an example which includes some R-code that will apply Francis Method TA 1.8 method #&#39; and automatically update a Casal2 estimation file library(Casal2) library(r4Casal2) library(ggplot2) library(dplyr) csl_dir = normalizePath(file.path(&quot;misc&quot;, &quot;AutomateDataWeighting&quot;,&quot;csls&quot;)) mpd = extract.mpd(file = &quot;estimate.log&quot;, path = csl_dir) obs_csl2 = extract.csl2.file(file = &quot;Observation.csl2&quot;, path = csl_dir) names(mpd) ## comp labels comp_labels = c(&quot;chatTANage&quot;, &quot;chatOBSwst&quot;, &quot;chatOBSest&quot;) ## check weights max_tolerance = abs(1 - Method.TA1.8(model = mpd, observation_labels = comp_labels, plot.it = F)) # Before running this it always pays to save a copy of the original Observation.csl2 # incase an error occurs and deletes the file or something silly ## run this line of code if(FALSE) file.copy(from = file.path(csl_dir, &quot;Observation.csl2&quot;), to = file.path(csl_dir, &quot;Observation_original.csl2&quot;)) # first run an estimation current_dir = getwd() setwd(csl_dir) system2(command = &quot;casal2&quot;, args = &quot;-e&quot;, stdout = paste0(&quot;estimate_&quot;,0,&quot;.log&quot;), stderr = &quot;estimate.err&quot;) setwd(current_dir) # to be even more sure, it pays to change the config.csl2 to work off !include with a different file. weighting_iterator = 1; weighted_mpds = list() while(max_tolerance &gt; 0.01) { cat(&quot;weighting loop index = &quot;, weighting_iterator, &quot; max tolerance = &quot;, max_tolerance, &quot;\\n&quot;); ## change observation.csl2 obs_csl2 = extract.csl2.file(file = &quot;Observation.csl2&quot;, path = csl_dir, quiet = T) # read in mpd mpd = extract.mpd(file = paste0(&quot;estimate_&quot;,weighting_iterator - 1,&quot;.log&quot;), path = csl_dir) weighted_mpds[[as.character(round(max_tolerance,3))]] = mpd vals = vector(); ## loop over each comp data set and weight individually for(comp_ndx in 1:length(comp_labels)) { # calculate weight weight = Method.TA1.8(model = mpd, observation_labels = comp_labels[comp_ndx], plot.it = F) # get the obs input file vals[comp_ndx] = weight this_obs = obs_csl2[[paste0(&quot;observation[&quot;,comp_labels[comp_ndx],&quot;]&quot;)]] # change the subcommand &#39;error_value_multiplier&#39; if(is.null(this_obs$error_value_multiplier)) { this_obs$error_value_multiplier = list() this_obs$error_value_multiplier$value = 10 } else { this_obs$error_value_multiplier$value = 10 } # the francis method wants weight = 1.0 # check if the tolerance approx = 1 if(abs(1 - weight) &gt; max_tolerance) max_tolerance = abs(1 - weight) # save the observation back into the overall config obs_csl2[[paste0(&quot;observation[&quot;,comp_labels[comp_ndx],&quot;]&quot;)]] = this_obs } ## priny the weights cat(comp_labels, &quot;\\n&quot;) cat(round(vals,5), &quot;\\n&quot;) ## write the file ## Note!! this will overwrite &#39;Observation.csl2&#39; it will strip out all comments as well write.csl2.file(obs_csl2, file = &quot;Observation.csl2&quot;, path = csl_dir) ## estimate the model with Casal2 current_dir = getwd() setwd(csl_dir) system2(command = &quot;casal2&quot;, args = &quot;-e&quot;, stdout = paste0(&quot;estimate_&quot;,weighting_iterator,&quot;.log&quot;), stderr = &quot;estimate.err&quot;) setwd(current_dir) weighting_iterator = weighting_iterator + 1 } 4.1.3 Model quantities Fishing Pressures Below illustrates code to plot fishing pressure, but you can also easily adapt the code to plot catches. One thing to note, is Casal2 will report both exploitation_rate and fishing_pressures. For models that only have a single fishery per time-step or area these will be the same. If there are multiple fisheries interacting with the partition then they will differ. Fishing pressure is the maximum exploitation applied to the partition for that time-step and area. See the user manual for more detail on the difference. exploitation_rate reported is just \\[ \\frac{catch}{vunerable} \\] Some R-code used to summarise fishing pressures. file_name = system.file(&quot;extdata&quot;, &quot;estimate.log&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) mpd = extract.mpd(file = file_name) # Report labels # names(mpd) # plot fishing pressures fishery_info = get_fisheries(mpd) head(fishery_info) # Note this will print both fishing pressure and exploitation my_plot = ggplot(fishery_info, aes(x = year, y = exploitation, col = fishery, linetype = fishery)) + geom_line(size =2) my_plot Flexibility using standard ggplot functions # you can add adjust it as you please, for example if you want 3 panels for each fishery my_plot + facet_wrap(~fishery) + theme(axis.text.x = element_text(angle = 90)) # Adjust ylim and add a reference limit my_plot + ylim(0,0.09) + geom_hline(yintercept = 0.05, linetype = &quot;dashed&quot;) 4.1.3.1 Plotting selectivities selectivity_df = get_selectivities(model = mpd) ggplot(selectivity_df, aes(x = bin, y = selectivity, col = label)) + geom_line(size = 1.5) + facet_wrap(~label) 4.2 Multiple Casal2 runs with -i or -s file_name = system.file(&quot;extdata&quot;, &quot;multi_run.out&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) mpd = extract.mpd(file = file_name) # Report labels # names(mpd) # plot fishing pressures my_plot = r4Casal2::plot.pressure(model = mpd, report_label = &quot;Instantaneous_Mortality&quot;) my_plot = my_plot + theme(axis.text.x = element_text(angle = 90)) # this will generate a generic ggplot print(my_plot) Plotting selectivities selectivity_df = get_selectivities(mpd) selectivity_df$par_set = factor(selectivity_df$par_set, ordered = T) ggplot(selectivity_df, aes(x = bin, y = selectivity, col = report_label, line_type = par_set)) + geom_line(size = 1.5) + facet_grid(par_set~report_label) Plotting Fits my_plot = plot.relative_index(model = mpd, report_labels = c(&quot;autumnTANbiomass&quot;, &quot;summerTANbiomass&quot;), plot.it = T, plot_type = &quot;classic&quot;) ## [1] &quot;multi iteration report found&quot; ## [1] &quot;multi iteration report found&quot; my_plot References "],["summarisemultipleinputs.html", "Chapter 5 Comparing multiple MPD runs 5.1 Read in models 5.2 Compare model outputs", " Chapter 5 Comparing multiple MPD runs 5.1 Read in models file_name_low_m = system.file(&quot;extdata&quot;, &quot;low_m.log&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) low_m_mpd = extract.mpd(file = file_name_low_m) file_name_high_m = system.file(&quot;extdata&quot;, &quot;high_m.log&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) high_m_mpd = extract.mpd(file = file_name_high_m) ## create a named list models = list(&quot;M = 0.22&quot; = low_m_mpd, &quot;M = 0.44&quot; = high_m_mpd) 5.2 Compare model outputs 5.2.1 selectivities selectivity_df = get_selectivities(models) ggplot(selectivity_df, aes(x = bin, y = selectivity, col = model_label, linetype = model_label)) + geom_line(size = 1.5) + facet_wrap(~label) + labs(x = &quot;Age&quot;, y = &quot;Ogive&quot;, col = &quot;Model&quot;, linetype = &quot;Model&quot;) 5.2.2 Derived quantities dq_df = get_dqs(models) dq_df$years = as.numeric(dq_df$years) ggplot(dq_df, aes(x = years, y = values, col = model_label, linetype = model_label)) + geom_line(size = 1.5) + facet_wrap(~dq_label) + labs(x = &quot;Year&quot;, y = &quot;SSB&quot;, col = &quot;Model&quot;, linetype = &quot;Model&quot;) 5.2.3 Recruitment recruit_df = get_BH_recruitment(models) ggplot(recruit_df, aes(x = ycs_years, y = standardised_ycs, col = model_label, linetype = model_label)) + geom_line(size = 1.3) + labs(x = &quot;YCS year&quot;, y = &quot;standardised ycs&quot;, col = &quot;Model&quot;, linetype = &quot;Model&quot;) 5.2.4 Abundance fits abundance_obs_df = get_abundance_observations(models) ggplot(abundance_obs_df, aes(x = year)) + geom_point(aes(y = observed), size = 1.4) + geom_line(aes(y = expected, col = model_label)) + labs(x = &quot;year&quot;, y = &quot;Abundance&quot;, col = &quot;Model&quot;, linetype = &quot;Model&quot;) + facet_wrap(~observation_label, scales = &quot;free&quot;) "],["mcmc.html", "Chapter 6 MCMC 6.1 Read in models 6.2 Diagnostics 6.3 Plotting quantities", " Chapter 6 MCMC Casal2 MCMC estimation for a single model should be done using “multiple chains”. A chain in this case is a seperate MCMC run, ideally starting from a different set of starting locations and with a different seed number. It is advised to create at least three chains per model. Most of the MCMC diagnostics in this package are designed for multiple chains. These include calculating Rhats (within and between chain variation in parameters) (Vehtari et al. 2021) and effective sample sizes which is a measure of effeciency in your mcmc sampler. 6.1 Read in models ## extra packages library(purrr) library(bayesplot) cas2_file_dir = system.file(&quot;extdata&quot;, &quot;multi_chain_mcmc&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) mcmc_1 = extract.mcmc(path = cas2_file_dir, samples.file = &quot;samples.4&quot;, objectives.file = &quot;objectives.4&quot;) mcmc_2 = extract.mcmc(path = cas2_file_dir, samples.file = &quot;samples.5&quot;, objectives.file = &quot;objectives.5&quot;) mcmc_3 = extract.mcmc(path = cas2_file_dir, samples.file = &quot;samples.6&quot;, objectives.file = &quot;objectives.6&quot;) ## assign chain label mcmc_1$chain = &quot;1&quot; mcmc_2$chain = &quot;2&quot; mcmc_3$chain = &quot;3&quot; ## Remove Burnin mcmc_post_1 = mcmc_1 %&gt;% filter(state == &quot;mcmc&quot;) mcmc_post_2 = mcmc_2 %&gt;% filter(state == &quot;mcmc&quot;) mcmc_post_3 = mcmc_3 %&gt;% filter(state == &quot;mcmc&quot;) ## combine mcmc_all = rbind(mcmc_1, mcmc_2, mcmc_3) mcmc_non_burn_in = mcmc_all %&gt;% filter(state == &quot;mcmc&quot;) n_posterior_samples = nrow(mcmc_post_1) + nrow(mcmc_post_2) + nrow(mcmc_post_3) ## do some modifying so we have just parameters available ## TODO: change parameter labels so they are not so large and easier to read on figures pars = colnames(mcmc_post_1[,12:(ncol(mcmc_non_burn_in) - 1)]) iters = max(nrow(mcmc_post_1), nrow(mcmc_post_2), nrow(mcmc_post_3)) bayes_array = array(dim = c(iters, 3, length(pars)), dimnames = list(1:iters, 1:3, pars)) bayes_array[1:nrow(mcmc_post_1),1,] = as.matrix(mcmc_post_1[,12:(ncol(mcmc_non_burn_in) - 1)]) bayes_array[1:nrow(mcmc_post_2),2,] = as.matrix(mcmc_post_2[,12:(ncol(mcmc_non_burn_in) - 1)]) bayes_array[1:nrow(mcmc_post_3),3,] = as.matrix(mcmc_post_3[,12:(ncol(mcmc_non_burn_in) - 1)]) ## cut off at min min_cutoff = min(nrow(mcmc_post_1), nrow(mcmc_post_2), nrow(mcmc_post_3)) bayes_array = bayes_array[1:min_cutoff, ,] 6.2 Diagnostics ## get Rhats rhats = apply(bayes_array, MARGIN = 3, Rhat) ## get effective sample sizes n_eff_bulk = apply(bayes_array, MARGIN = 3, ess_bulk) n_eff_tail = apply(bayes_array, MARGIN = 3, ess_tail) ## TODO: need to think about what is a good general rule of thumb. ## I was thinking you would want n_eff of at least 200. The Rhat function produces R-hat convergence diagnostic, which compares the between- and within-chain estimates for model parameters and other univariate quantities of interest. Chains that have not mixed well (i.e., the between-and within-chain estimates don’t agree) will result in R-hat larger than 1.1. The ess_bulk function produces an estimated Bulk Effective Sample Size (bulk-ESS) using rank normalized draws. Bulk-ESS is useful measure for sampling efficiency in the bulk of the distribution (related e.g. to efficiency of mean and median estimates), and is well defined even if the chains do not have finite mean or variance. The ess_tail function produces an estimated Tail Effective Sample Size (tail-ESS) by computing the minimum of effective sample sizes for 5% and 95% quantiles. Tail-ESS is useful measure for sampling efficiency in the tails of the distribution (related e.g. to efficiency of variance and tail quantile estimates). Once you have calculated these quantities you can use bayesplot plotting functions. Need to work on changing parameter labels from the Casal2 model. They make some of these plots difficult to read mcmc_rhat(rhats) ## Warning: Dropped 6 NAs from &#39;new_rhat(rhat)&#39;. #mcmc_neff(n_eff_bulk) #mcmc_neff(n_eff_tail) 6.3 Plotting quantities ## This function helps create 95% CIs for quantities p &lt;- c(0.025, 0.5, 0.975) ## confidence intervals p_names &lt;- map_chr(p, ~paste0(.x*100, &quot;%&quot;)) p_funs &lt;- map(p, ~partial(quantile, probs = .x, na.rm = TRUE)) %&gt;% rlang::set_names(nm = c(&quot;low&quot;, &quot;mid&quot;, &quot;upp&quot;)) #p_funs ## Bring in derived quantities cas2_file_name = system.file(&quot;extdata&quot;, &quot;tabular.log&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) cas2_tab = extract.tabular(file = cas2_file_name, quiet = T) ## cut off burn-in the first 50 samples cas2_tab = burn.in.tabular(cas2_tab, Row = 50) 6.3.1 selectivities selectivity_df = get_selectivities(cas2_tab) quantile_selectivity_df = selectivity_df %&gt;% group_by(bin, selectivity_label) %&gt;% summarize_at(vars(selectivity), p_funs) ggplot(quantile_selectivity_df, aes(x = bin)) + geom_ribbon(aes(ymax = low, ymin = upp, alpha = 0.5, col = selectivity_label, fill = selectivity_label), lwd=0) + geom_line(aes(y = mid, col = selectivity_label, group = selectivity_label), size =2, alpha = 1) + facet_wrap(~selectivity_label) + labs(x = &quot;Age&quot;, y = &quot;Ogive&quot;, col = &quot;Model&quot;, linetype = &quot;Model&quot;) 6.3.2 Derived quantities # plot Ssbs ssbs = get_derived_quanitites(model = cas2_tab) ## getting values for SSB_E ## getting values for SSB_W #ssbs_mpd = get_derived_quanitites(model = mpd) #head(ssbs) #ssbs_mpd$years = as.numeric(ssbs_mpd$years) ssbs$years[ssbs$years == &quot;initialisation_phase_1&quot;] = 1971 quantile_ssb_df = ssbs %&gt;% group_by(years, dq_label) %&gt;% summarize_at(vars(values), p_funs) quantile_ssb_df$years = as.numeric(quantile_ssb_df$years) ## quant_ssb_plot = ggplot(quantile_ssb_df, aes(x = years)) + geom_ribbon(aes(ymax = low, ymin = upp, alpha = 0.5, col = dq_label, fill = dq_label), lwd=0) + theme_bw() + geom_line(aes(y = mid, col = dq_label, group = dq_label), size =2, alpha = 1) + xlab(&quot;Years&quot;) + ylab(&quot;SSB&quot;) + ylim(0, 2500000) + xlim(1970, 2020) + scale_alpha(guide = &#39;none&#39;) + #geom_line(data = ssbs_mpd, aes(x = years, y = values), inherit.aes = F, col = &quot;black&quot;, size = 1.5) + facet_wrap(~dq_label) quant_ssb_plot References "],["PPC.html", "Chapter 7 Posterior Predictive Checks 7.1 Introduction 7.2 Estimation 7.3 Simulations 7.4 Summarising simulated data in R 7.5 Posterior predictive checks 7.6 PIT residuals", " Chapter 7 Posterior Predictive Checks 7.1 Introduction This vignette demonstrates how to use Casal2s simulation mode with r4Casal2 R functions to generate posterior predictive checks for goodness of fit measures. In terms of assessment workflow, this falls in the Diagnostic component. The following vignette uses the Casal2 model embedded into this R package. If you want to see where this is on you system paste the following line of code into your R console system.file(\"extdata\", \"PosteriorPredictiveChecks\", package = \"r4Casal2\") Assessment Process 7.2 Estimation Before looking at data goodness of fit you should be checking if the model has converged. We assume that the estimated model has satisfied this criteria i.e. invertable covariance, acceptable gradient (close to zero) and global minima (apposed to local try jittering start values). library(DHARMa) ## This is DHARMa 0.4.5. For overview type &#39;?DHARMa&#39;. For recent changes, type news(package = &#39;DHARMa&#39;) library(mvtnorm) ## if simulating obs at MPD mpd_file_name = system.file(&quot;extdata&quot;, &quot;PosteriorPredictiveChecks&quot;,&quot;estimate.log&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) mpd = extract.mpd(file = mpd_file_name) ## WARNING: The output file was generated with a different version than the R libray being used to read the output. ## This may cause compatibility issues. Please update the R package to be consistent with the version of Casal2 used to generate the output. ## The output was generated with Casal2 v(c) 2 ## The Casal2 R package is compatible with Casal2 v22.05 # Report labels names(mpd) ## [1] &quot;header&quot; &quot;obj&quot; &quot;estimate_summary&quot; ## [4] &quot;covar&quot; &quot;hess&quot; &quot;estimate_value&quot; ## [7] &quot;biomass_t1&quot; &quot;chatOBSest&quot; &quot;chatOBSwst&quot; ## [10] &quot;chatTANage&quot; &quot;chatTANbiomass&quot; &quot;Recruitment&quot; ## [13] &quot;Ageing&quot; &quot;instant_mort&quot; &quot;MaturationSel&quot; ## [16] &quot;westFSel&quot; &quot;eastFSel&quot; &quot;chatTANSel&quot; ## [19] &quot;One&quot; &quot;messages_encountered&quot; # is covariance symetric isSymmetric(mpd$covar$covariance_matrix) ## [1] TRUE # is hessian invertable is_matrix_invertable(mpd$hess$hessian_matrix) ## [1] TRUE 7.3 Simulations The first thing you should do is add reports of type simulated_observation for each observation in your Casal2 configuration files. The helper function ?create_simulation_reports will automatically generate a casal2 compatible reports to a file named simulated_reports.csl2 containing all simulated observations in your configuration files. If you use this function you will need to then add an include statement into your Casal2 config files i.e. !include simulated_reports.csl2 before running casal2 in simulation mode casal2 -s 1. config_dir = system.file(&quot;extdata&quot;, &quot;PosteriorPredictiveChecks&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) config_files = &quot;Observation.csl2&quot; ## this will create the file &#39;simulated_reports.csl2&#39; in config_dir ## in addition to creating the directory labelled output_folder obs = create_simulation_reports(config_dir = config_dir, config_files = config_files, output_folder = &quot;simulated_observations&quot;) ## append include statement if(FALSE) cat(&quot;!include simulated_reports.csl2&quot;, file = file.path(config_dir, &quot;config.csl2&quot;), append = T) ## run Casal2 -s # system(paste0(&quot;cd &quot;, config_dir, &quot;; casal2 -s 100 -i pars&quot; )) If you don’t have these reports in your configuration files, Casal2 will not save simulated observations. Tips when specifying this report class Save each simulated observation into a seperate file_name Create a directory to save simulated data sets in. Have the report label the same as the file_name (see example below) Avoid haveing periods/dots (“.”) in file_name An example report structure would look like @report sim_chatTANage type simulated_observation observation chatTANage file_name simulated_observations/sim_chatTANage There are three variants of simulations you can conduct in Casal2, and these depend on if you are in MPD or MCMC estimation phase. If you are evaluating a MPD run, there are two variants and depend if you want to account for parameter uncertainty or not. If you don’t want parameter uncertainty, then you need to run the following Casal2 command to produce 100 sets of simulations casal2 -s 100 -i mpd_pars.log &gt; simulate.log. If you want to account for parameter uncertainty then you can use a multivariant normal distribution with mean equal to MPD and resulting covariance to produce a set of simulations, example below. n_sims = 1000 ## NOTE: might have issue with bounds assuming normal dist sims = rmvnorm(n = n_sims, mean = as.numeric(mpd$estimate_value$values), sigma = mpd$covar$covariance_matrix) dim(sims) ## [1] 1000 46 colnames(sims) = names(mpd$estimate_value$values) ## save simulated pars in the same directory as your ## CSL files if(FALSE) write.table(sims, file = &quot;mpd_mvnorm_pars.csl2&quot;, quote = F, row.names = F, col.names = T) # run # casal2 -s 1 -i mpd_mvnorm_pars.csl2 &gt; simulate.log 7.4 Summarising simulated data in R Assuming you have saved all the simulated observations as separate files in a standalone folder. sim_dir = system.file(&quot;extdata&quot;, &quot;PosteriorPredictiveChecks&quot;,&quot;simulated_observations&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) ## created from running simulations and reading them in with # sim_vals = read.simulated.data(dir = sim_dir, mean_age = F) # saveRDS(sim_vals, file.path(&quot;sim_vals.RDS&quot;)) sim_vals = readRDS(file.path(sim_dir, &quot;sim_vals.RDS&quot;)) # check no trouble with files sim_vals$failed_files ## logical(0) # names(sim_vals$sim_obs) ## [1] &quot;sim_chatOBSest&quot; &quot;sim_chatOBSwst&quot; &quot;sim_chatTANage&quot; ## [4] &quot;sim_chatTANbiomass&quot; sim_dir_alt = system.file(&quot;extdata&quot;, &quot;PosteriorPredictiveChecks&quot;,&quot;simulated_observations_no_param_var&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) #sim_vals_alt = read.simulated.data(dir = sim_dir_alt, mean_age = F) #saveRDS(sim_vals_alt, file.path(&quot;sim_vals_alt.RDS&quot;)) sim_vals_alt = readRDS(file.path(sim_dir_alt, &quot;sim_vals_alt.RDS&quot;)) # check no trouble with reading in files sim_vals_alt$failed_files ## logical(0) # names(sim_vals_alt$sim_obs) ## [1] &quot;sim_chatOBSest&quot; &quot;sim_chatOBSwst&quot; &quot;sim_chatTANage&quot; ## [4] &quot;sim_chatTANbiomass&quot; 7.5 Posterior predictive checks Once simulated data has been read into the R environment, we want to compare where the observed values fall relative to the posterior predictive distributions. We recommend using the DHarma r package for this. To intepret P-values or understand the test-statistics that DHARMa does copy this into your R console vignette(\"DHARMa\", package=\"DHARMa\") (Assuming you have installed this package). ## Create DHARMa objects and P-values DHARMaResbio = createDHARMa(simulatedResponse = sim_vals$sim_obs$sim_chatTANbiomass, observedResponse = mpd$chatTANbiomass$Values$observed, fittedPredictedResponse = mpd$chatTANbiomass$Values$expected, integerResponse = F) ## Create DHARMa objects and P-values ## for AF mpd$chatTANage$Values$numbers_at_age = mpd$chatTANage$Values$observed * mpd$chatTANage$Values$error_value year = 1999 obs = mpd$chatTANage$Values$numbers_at_age[mpd$chatTANage$Values$year == year] DHARMaResAF = createDHARMa(simulatedResponse = sim_vals$sim_obs$sim_chatTANage[[as.character(year)]], observedResponse = obs, fittedPredictedResponse = NULL, integerResponse = F) ## No fitted predicted response provided, using the mean of the simulations ## use DHARMa functions plot(DHARMaResbio, quantreg = F) plot(DHARMaResAF, quantreg = F) Examples of custom plots sim_chatTANbiomass = sim_vals$sim_obs$sim_chatTANbiomass rownames(sim_chatTANbiomass) = mpd$chatTANbiomass$Values$year DHARMaResbio_quant_resids = createDHARMa(simulatedResponse = sim_chatTANbiomass, observedResponse = mpd$chatTANbiomass$Values$observed, fittedPredictedResponse = mpd$chatTANbiomass$Values$expected, integerResponse = F) ## convert from uniform variable -&gt; standard normal norm_quant_resids = qnorm(DHARMaResbio_quant_resids$scaledResiduals) # formal tests #dispersion_test = testDispersion(DHARMaResbio_quant_resids) #zero_inflat_test = testZeroInflation(DHARMaResbio_quant_resids) temporal_correlation = testTemporalAutocorrelation(simulationOutput = DHARMaResbio_quant_resids, time = mpd$chatTANbiomass$Values$year, plot = F) ## HO: rho = 0, HA: rho != 0 temporal_correlation ## ## Durbin-Watson test ## ## data: simulationOutput$scaledResiduals ~ 1 ## DW = 1.9861, p-value = 0.9743 ## alternative hypothesis: true autocorrelation is not 0 ## plot posterior predictive checks bioplt = plot_abundance_predictive_dist(sim_data = sim_chatTANbiomass, obs = data.frame(obs = mpd$chatTANbiomass$Values$observed, year = mpd$chatTANbiomass$Values$year, mpd_fit = mpd$chatTANbiomass$Values$expected), lab = &quot;&quot;, plot_type = &quot;violin&quot;) ## Warning in regularize.values(x, y, ties, missing(ties), na.rm = na.rm): ## collapsing to unique &#39;x&#39; values bioplt= bioplt + theme(axis.text.x = element_text(angle = 90)) + ggtitle(&quot;MPD Predictive distributions&quot;) ## qq plot for simulated quantile residuals. norm_resid = ggplot(data.frame(resids = norm_quant_resids), aes(sample = resids)) + stat_qq(size = 3) + stat_qq_line(col = &quot;steelblue&quot;, size = 1.5, linetype = &quot;dashed&quot;) + labs(x = &quot;Theoretical&quot;, y = &quot;Sample&quot;) ## Plot normalised residuals generated from Casal2 normalised_resids = ggplot(mpd$chatTANbiomass$Values, aes(sample = normalised_residuals)) + stat_qq(size = 3) + stat_qq_line(col = &quot;steelblue&quot;, size = 1.5, linetype = &quot;dashed&quot;) + labs(x = &quot;Theoretical&quot;, y = &quot;Sample&quot;) ## Plot fits obs fits = plot.relative_index(model = mpd, report_label = &quot;chatTANbiomass&quot;) + ggtitle(&quot;&quot;) ## fits Look at Predictive checks when generated with variability in parameter estimates as well. ## Create DHARMa objects and P-values DHARMaResbio = createDHARMa(simulatedResponse = sim_vals_alt$sim_obs$sim_chatTANbiomass, observedResponse = mpd$chatTANbiomass$Values$observed, fittedPredictedResponse = mpd$chatTANbiomass$Values$expected, integerResponse = F) ## Create DHARMa objects and P-values ## for AF year = 2000 obs = mpd$chatTANage$Values$numbers_at_age[mpd$chatTANage$Values$year == year] DHARMaResAF = createDHARMa(simulatedResponse = sim_vals_alt$sim_obs$sim_chatTANage[[as.character(year)]], observedResponse = obs, fittedPredictedResponse = NULL, integerResponse = T) ## No fitted predicted response provided, using the mean of the simulations plot(DHARMaResbio, quantreg = F) plot(DHARMaResAF, quantreg = F) Some other visualizations plots ######################## ## boxplot predictive distribution vs observation legend = c(&quot;Posterior Prediction&quot; = &quot;#56B4E9&quot;, &quot;Observation&quot; = &quot;black&quot; , &quot;MPD&quot; = &quot;#D55E00&quot;) sim_data = sim_vals$sim_obs$sim_chatTANbiomass rownames(sim_data) = mpd$chatTANbiomass$Values$year bioplt = plot_abundance_predictive_dist(sim_data = sim_data, obs = data.frame(obs = mpd$chatTANbiomass$Values$observed, year = mpd$chatTANbiomass$Values$year, mpd_fit = mpd$chatTANbiomass$Values$expected), lab = &quot;chatTANbiomass&quot;, plot_type = &quot;violin&quot;) ## Warning in regularize.values(x, y, ties, missing(ties), na.rm = na.rm): ## collapsing to unique &#39;x&#39; values chat_sim_vals = get_simulated_age_resids(sim_vals$sim_obs$sim_chatTANage, mpd$chatTANage) obs_years = unique(chat_sim_vals$mpd_df$year) years_to_plot = obs_years[1:12] pppAFplt_1 = ggplot(chat_sim_vals$full_simulated_values %&gt;% filter(year %in% years_to_plot), aes(x = factor(age, ordered = T), y = simulated_value)) + geom_violin(aes(color = &quot;Posterior Prediction&quot;, fill = &quot;Posterior Prediction&quot;),adjust=2) + scale_color_manual(values = legend) + guides(fill = &quot;none&quot;) + theme(axis.text.x = element_text(angle = 45)) + labs(colour = &quot;Legend&quot;, x = &quot;Age&quot;, y = &quot;Posterior Predictive Distribution&quot;) + geom_point(data = chat_sim_vals$mpd_df %&gt;% filter(year %in% years_to_plot), aes(x = factor(age, ordered = T), y = observed * error_value, color = &quot;Observation&quot;, fill = &quot;Observation&quot;), size = 2.4, inherit.aes = F ) + facet_wrap(~year, scales = &quot;free_y&quot;, ncol = 3) + ggtitle(&quot;chatTANage&quot;) pppAFplt_1 OM_file = system.file(&quot;extdata&quot;, &quot;PosteriorPredictiveChecks&quot;,&quot;OM&quot;,&quot;OM_vary.log&quot;, package = &quot;r4Casal2&quot;, mustWork = TRUE) OM_run = extract.mpd(file = OM_file) ## WARNING: The output file was generated with a different version than the R libray being used to read the output. ## This may cause compatibility issues. Please update the R package to be consistent with the version of Casal2 used to generate the output. ## The output was generated with Casal2 v(c) 2 ## The Casal2 R package is compatible with Casal2 v22.05 ## ## loading a Casal2 output from a multi parameter input format ## loading a Casal2 output from a multi parameter input format ## plot SSBs my_plot = r4Casal2::plot.derived_quantities(model = list(OM = OM_run, EM = mpd), report_label = &quot;biomass_t1&quot;) ## [1] &quot;multi iteration report found&quot; my_plot = my_plot + xlab(&quot;SSB&quot;) + ylim(0, 120000) 7.6 PIT residuals Pearson residuals for multinomial distributed random variables can be difficult to intepret for a lot of reasons, data-weighting for mean age to standardised residuals = 1 (Francis 2011), sparsity can create funny patterns etc. An alternative is to use randomised quantile PIT residuals (Warton, Thibaut, and Wang 2017; Dunn and Smyth 1996) Assuming we have data denoted by \\(y\\) which has cumulative distribution function \\(F(y; \\theta), u = F(y; \\theta) \\sim Uniform(0,1)\\). For discrete variables the following adjustment can be made \\[\\begin{align} u_i = q_i F(y; \\theta) + (1 - q_i) F(y^{-}; \\theta) \\end{align}\\] where, \\(q_i\\) is a standard uniform random variable and \\(y^{-}\\) is the previous allowable value for \\(y\\). they do not behave like residuals in the usual sense they are centred around a value of 0.5 rather than a value of 0, and are bounded between 0 and 1. # hello set.seed(123) n = 50 nsims = 1000 x = rnorm(n, 5, 3) beta0 = 3 beta1 = 1.2 true_beta1 = 1 y = rpois(n, beta0 + true_beta1 * x) y_sim = matrix(nrow = n, ncol = nsims) for(i in 1:nsims) y_sim[,i] = rpois(n, beta0 + beta1 * x) ## calculate PIT PITResiduals = rep(NA, n) altPITResiduals = rep(NA, n) for (i in 1:n){ minSim &lt;- mean(y_sim[i,] &lt; y[i]) maxSim &lt;- mean(y_sim[i,] &lt;= y[i]) if (minSim == maxSim) { PITResiduals[i] = minSim } else { PITResiduals[i] = runif(1, minSim, maxSim) } qi = runif(1) lower_limit = mean(y_sim[i,] &lt; y[i]) cum_ecdf = mean(y_sim[i,] &lt;= y[i]) altPITResiduals[i] = qi * cum_ecdf + (1 - qi) * lower_limit } plot(PITResiduals, altPITResiduals) # It is assumed that PIT resiudals are from uniform(0,1) # most people transform them to normal distribution for testing # for familiarity more than anything. normal_transformed = qnorm(PITResiduals) qqnorm(normal_transformed) qqline(normal_transformed, col = &quot;steelblue&quot;, lwd = 3, lty = 2) shapiro.test(normal_transformed) ## ## Shapiro-Wilk normality test ## ## data: normal_transformed ## W = 0.97169, p-value = 0.2707 # From the output, the p-value &gt; 0.05 implying that the distribution # of the data are not significantly different from normal distribution. # In other words, we can assume the normality. References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
